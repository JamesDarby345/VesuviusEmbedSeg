{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/james/Documents/VS/EmbedSegScrolls')\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from EmbedSeg.train import begin_training\n",
    "from EmbedSeg.utils.create_dicts import create_dataset_dict, create_model_dict, create_loss_dict, create_configs\n",
    "from matplotlib.colors import ListedColormap\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the path to `train`, `val` crops and the type of `center` embedding which we would like to train the network for:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train-val images, masks and center-images will be accessed from the path specified by `data_dir` and `project-name`.\n",
    "<a id='center'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Name chosen as : Vesuvius. \n",
      "Train-Val images-masks-center-images will be accessed from : crops\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'crops'\n",
    "project_name = 'Vesuvius'\n",
    "center = 'approximate-medoid' # 'centroid', 'medoid'\n",
    "\n",
    "print(\"Project Name chosen as : {}. \\nTrain-Val images-masks-center-images will be accessed from : {}\".format(project_name, data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Embedding Location chosen as : approximate-medoid\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert center in {'medoid', 'centroid', 'approximate-medoid'}\n",
    "    print(\"Spatial Embedding Location chosen as : {}\".format(center))\n",
    "except AssertionError as e:\n",
    "    e.args += ('Please specify center as one of : {\"medoid\", \"centroid\"}', 42)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain properties of the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we read the `dataset.json` file prepared in the `01-data` notebook previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('data_properties.json'): \n",
    "    with open('data_properties.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        data_type, foreground_weight, n_z, n_y, n_x, pixel_size_z_microns, pixel_size_x_microns = data['data_type'], float(data['foreground_weight']), int(data['n_z']), int(data['n_y']), int(data['n_x']), float(data['pixel_size_z_microns']), float(data['pixel_size_x_microns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify training dataset-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints: \n",
    "* The `train_size` attribute indicates the number of image-mask paired examples which the network would see in one complete epoch. Ideally this should be the number of `train` image crops. \n",
    "\n",
    "In the cell after this one, a `train_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_size = len(os.listdir(os.path.join(data_dir, project_name, 'train', 'images')))\n",
    "train_batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `train_dataset_dict` dictionary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`train_dataset_dict` dictionary successfully created                 with: \n",
      " -- train images accessed from crops/Vesuvius/train/images, \n",
      " -- number of images per epoch equal to 23, \n",
      " -- batch size set at 1, \n"
     ]
    }
   ],
   "source": [
    "train_dataset_dict = create_dataset_dict(data_dir = data_dir, \n",
    "                                         project_name = project_name,  \n",
    "                                         center = center, \n",
    "                                         size = train_size, \n",
    "                                         batch_size = train_batch_size, \n",
    "                                         type = 'train',\n",
    "                                         name = '3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify validation dataset-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* The size attribute indicates the number of image-mask paired examples which the network would see in one complete epoch. Here, it is recommended to set `val_size` equal to the total number of validation image crops.\n",
    "\n",
    "In the cell after this one, a `val_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "val_size = len(os.listdir(os.path.join(data_dir, project_name, 'val', 'images')))\n",
    "val_batch_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `val_dataset_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`val_dataset_dict` dictionary successfully created                 with: \n",
      " -- val images accessed from crops/Vesuvius/val/images, \n",
      " -- number of images per epoch equal to 9, \n",
      " -- batch size set at 1, \n"
     ]
    }
   ],
   "source": [
    "val_dataset_dict = create_dataset_dict(data_dir = data_dir, \n",
    "                                       project_name = project_name, \n",
    "                                       center = center, \n",
    "                                       size = val_size, \n",
    "                                       batch_size = val_batch_size, \n",
    "                                       type ='val',\n",
    "                                       name ='3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify model-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* Set the `input_channels` attribute equal to the number of channels in the input images. \n",
    "* Set the `num_classes = [6, 1]` for `3d` training and `num_classes = [4, 1]` for `2d` training\n",
    "<br>(here, 6 implies the offsets and bandwidths in x, y and z dimensions and 1 implies the `seediness` value per pixel)\n",
    "\n",
    "In the cell after this one, a `model_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "num_classes = [6, 1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `model_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`model_dict` dictionary successfully created                 with: \n",
      " -- num of classes equal to 1, \n",
      " -- input channels                 equal to [6, 1], \n",
      " -- name equal to branched_erfnet_3d\n"
     ]
    }
   ],
   "source": [
    "model_dict = create_model_dict(input_channels = input_channels,\n",
    "                              num_classes = num_classes,\n",
    "                              name = '3d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `loss_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`loss_dict` dictionary successfully created                 with: \n",
      " -- foreground weight equal to 3.708, \n",
      " -- w_inst                 equal to 1, \n",
      " -- w_var                 equal to 10, \n",
      " -- w_seed equal to 1\n"
     ]
    }
   ],
   "source": [
    "loss_dict = create_loss_dict(n_sigma = 3, foreground_weight = foreground_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify additional parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "* The `n_epochs` attribute determines how long the training should proceed. In general for reasonable results, you should atleast train for longer than 50 epochs.\n",
    "* The `save_dir` attribute identifies the location where the checkpoints and loss curve details are saved. \n",
    "* If one wishes to **resume training** from a previous checkpoint, they could point `resume_path` attribute appropriately. For example, one could set `resume_path = './experiment/Mouse-Organoid-Cells-CBG-demo/checkpoint.pth'` to resume training from the last checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "save_dir = os.path.join('experiment', project_name+'-'+'demo')\n",
    "resume_path  = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell after this one, a `configs` dictionary is generated from the parameters specified here!\n",
    "<a id='resume'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the  `configs` dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`configs` dictionary successfully created with: \n",
      " -- n_epochs equal to 50, \n",
      " -- save_dir equal to experiment/Vesuvius-demo, \n",
      " -- n_z equal to 256, \n",
      " -- n_y equal to 256, \n",
      " -- n_x equal to 256, \n"
     ]
    }
   ],
   "source": [
    "configs = create_configs(n_epochs = n_epochs,\n",
    "                         resume_path = resume_path, \n",
    "                         save_dir = save_dir, \n",
    "                         n_z = n_z,\n",
    "                         n_y = n_y, \n",
    "                         n_x = n_x,\n",
    "                         anisotropy_factor = pixel_size_z_microns/pixel_size_x_microns, \n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Checks if CUDA is available on your system\n",
    "print(torch.version.cuda)         # Shows the CUDA version PyTorch was built with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the next cell would begin the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-D `train` dataloader created! Accessing data from crops/Vesuvius/train/\n",
      "Number of images in `train` directory is 23\n",
      "Number of instances in `train` directory is 23\n",
      "Number of center images in `train` directory is 23\n",
      "*************************\n",
      "3-D `val` dataloader created! Accessing data from crops/Vesuvius/val/\n",
      "Number of images in `val` directory is 9\n",
      "Number of instances in `val` directory is 9\n",
      "Number of center images in `val` directory is 9\n",
      "*************************\n",
      "Creating Branched Erfnet 3D with [6, 1] outputs\n",
      "initialize last layer with size:  torch.Size([16, 6, 2, 2, 2])\n",
      "Created spatial emb loss function with:                     n_sigma: 3, foreground_weight: 3.7082556884380753\n",
      "*************************\n",
      "Created logger with keys:  ('train', 'val', 'iou')\n",
      "Starting epoch 0\n",
      "learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.53it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 2.36\n",
      "===> val loss: 2.50, val iou: 0.00\n",
      "=> saving checkpoint\n",
      "Starting epoch 1\n",
      "learning rate: 0.0004977494364660346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.57it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 2.23\n",
      "===> val loss: 2.30, val iou: 0.00\n",
      "=> saving checkpoint\n",
      "Starting epoch 2\n",
      "learning rate: 0.0004954977417064171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.54it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 2.18\n",
      "===> val loss: 2.18, val iou: 0.00\n",
      "=> saving checkpoint\n",
      "Starting epoch 3\n",
      "learning rate: 0.0004932449094349202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.49it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 2.12\n",
      "===> val loss: 2.11, val iou: 0.00\n",
      "=> saving checkpoint\n",
      "Starting epoch 4\n",
      "learning rate: 0.0004909909332982877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.55it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 2.09\n",
      "===> val loss: 2.08, val iou: 0.00\n",
      "=> saving checkpoint\n",
      "Starting epoch 5\n",
      "learning rate: 0.0004887358068751748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 2.06\n",
      "===> val loss: 2.05, val iou: 0.00\n",
      "=> saving checkpoint\n",
      "Starting epoch 6\n",
      "learning rate: 0.0004864795236750653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.55it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 2.05\n",
      "===> val loss: 2.04, val iou: 0.00\n",
      "=> saving checkpoint\n",
      "Starting epoch 7\n",
      "learning rate: 0.00048422207713716544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 2.03\n",
      "===> val loss: 2.04, val iou: 0.00\n",
      "=> saving checkpoint\n",
      "Starting epoch 8\n",
      "learning rate: 0.00048196346062927547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.51it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.89\n",
      "===> val loss: 2.75, val iou: 0.02\n",
      "=> saving checkpoint\n",
      "Starting epoch 9\n",
      "learning rate: 0.00047970366744663594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.49it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.53\n",
      "===> val loss: 1.91, val iou: 0.10\n",
      "=> saving checkpoint\n",
      "Starting epoch 10\n",
      "learning rate: 0.00047744269081074987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.56it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.46\n",
      "===> val loss: 1.97, val iou: 0.10\n",
      "=> saving checkpoint\n",
      "Starting epoch 11\n",
      "learning rate: 0.0004751805238681794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.60it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.47\n",
      "===> val loss: 1.80, val iou: 0.10\n",
      "=> saving checkpoint\n",
      "Starting epoch 12\n",
      "learning rate: 0.000472917159689316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.60it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.45\n",
      "===> val loss: 1.70, val iou: 0.11\n",
      "=> saving checkpoint\n",
      "Starting epoch 13\n",
      "learning rate: 0.00047065259126712457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.43\n",
      "===> val loss: 1.79, val iou: 0.10\n",
      "=> saving checkpoint\n",
      "Starting epoch 14\n",
      "learning rate: 0.00046838681151585874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.57it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.41\n",
      "===> val loss: 1.85, val iou: 0.09\n",
      "=> saving checkpoint\n",
      "Starting epoch 15\n",
      "learning rate: 0.0004661198132697498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.51it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.49\n",
      "===> val loss: 1.79, val iou: 0.11\n",
      "=> saving checkpoint\n",
      "Starting epoch 16\n",
      "learning rate: 0.0004638515892816641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.55it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.38\n",
      "===> val loss: 1.81, val iou: 0.10\n",
      "=> saving checkpoint\n",
      "Starting epoch 17\n",
      "learning rate: 0.00046158213222173284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.57it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.39\n",
      "===> val loss: 1.79, val iou: 0.10\n",
      "=> saving checkpoint\n",
      "Starting epoch 18\n",
      "learning rate: 0.0004593114346759497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.53it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.39\n",
      "===> val loss: 1.82, val iou: 0.11\n",
      "=> saving checkpoint\n",
      "Starting epoch 19\n",
      "learning rate: 0.00045703948914473726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.34\n",
      "===> val loss: 1.80, val iou: 0.10\n",
      "=> saving checkpoint\n",
      "Starting epoch 20\n",
      "learning rate: 0.00045476628804148113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.52it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.37\n",
      "===> val loss: 1.83, val iou: 0.11\n",
      "=> saving checkpoint\n",
      "Starting epoch 21\n",
      "learning rate: 0.00045249182369103055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.54it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.32\n",
      "===> val loss: 1.67, val iou: 0.12\n",
      "=> saving checkpoint\n",
      "Starting epoch 22\n",
      "learning rate: 0.00045021608832816447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.52it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.34\n",
      "===> val loss: 1.95, val iou: 0.10\n",
      "=> saving checkpoint\n",
      "Starting epoch 23\n",
      "learning rate: 0.0004479390740960227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.54it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.31\n",
      "===> val loss: 1.71, val iou: 0.12\n",
      "=> saving checkpoint\n",
      "Starting epoch 24\n",
      "learning rate: 0.00044566077304449995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.28\n",
      "===> val loss: 1.75, val iou: 0.13\n",
      "=> saving checkpoint\n",
      "Starting epoch 25\n",
      "learning rate: 0.00044338117712860363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.25\n",
      "===> val loss: 1.66, val iou: 0.13\n",
      "=> saving checkpoint\n",
      "Starting epoch 26\n",
      "learning rate: 0.00044110027820677195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.58it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.31\n",
      "===> val loss: 1.66, val iou: 0.13\n",
      "=> saving checkpoint\n",
      "Starting epoch 27\n",
      "learning rate: 0.000438818068039153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.55it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.26\n",
      "===> val loss: 1.61, val iou: 0.15\n",
      "=> saving checkpoint\n",
      "Starting epoch 28\n",
      "learning rate: 0.000436534538285843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.52it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.17\n",
      "===> val loss: 1.66, val iou: 0.15\n",
      "=> saving checkpoint\n",
      "Starting epoch 29\n",
      "learning rate: 0.00043424968050508256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.51it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.13\n",
      "===> val loss: 1.67, val iou: 0.14\n",
      "=> saving checkpoint\n",
      "Starting epoch 30\n",
      "learning rate: 0.00043196348615140955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.55it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.19\n",
      "===> val loss: 1.59, val iou: 0.14\n",
      "=> saving checkpoint\n",
      "Starting epoch 31\n",
      "learning rate: 0.0004296759465737673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.51it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.13\n",
      "===> val loss: 1.62, val iou: 0.14\n",
      "=> saving checkpoint\n",
      "Starting epoch 32\n",
      "learning rate: 0.00042738705301356716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.57it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.11\n",
      "===> val loss: 1.86, val iou: 0.14\n",
      "=> saving checkpoint\n",
      "Starting epoch 33\n",
      "learning rate: 0.0004250967966027037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.56it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.11\n",
      "===> val loss: 1.54, val iou: 0.18\n",
      "=> saving checkpoint\n",
      "Starting epoch 34\n",
      "learning rate: 0.00042280516836152096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.54it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.08\n",
      "===> val loss: 1.57, val iou: 0.16\n",
      "=> saving checkpoint\n",
      "Starting epoch 35\n",
      "learning rate: 0.00042051215919672877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.49it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.02\n",
      "===> val loss: 1.55, val iou: 0.15\n",
      "=> saving checkpoint\n",
      "Starting epoch 36\n",
      "learning rate: 0.00041821775989926696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.53it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.12\n",
      "===> val loss: 1.56, val iou: 0.16\n",
      "=> saving checkpoint\n",
      "Starting epoch 37\n",
      "learning rate: 0.00041592196114211634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.58it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.04\n",
      "===> val loss: 1.67, val iou: 0.16\n",
      "=> saving checkpoint\n",
      "Starting epoch 38\n",
      "learning rate: 0.0004136247534780547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.51it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.03\n",
      "===> val loss: 1.57, val iou: 0.18\n",
      "=> saving checkpoint\n",
      "Starting epoch 39\n",
      "learning rate: 0.00041132612733735566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.58it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.98\n",
      "===> val loss: 1.64, val iou: 0.18\n",
      "=> saving checkpoint\n",
      "Starting epoch 40\n",
      "learning rate: 0.00040902607302542923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.58it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.02\n",
      "===> val loss: 1.54, val iou: 0.17\n",
      "=> saving checkpoint\n",
      "Starting epoch 41\n",
      "learning rate: 0.00040672458072040163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.55it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.02\n",
      "===> val loss: 1.62, val iou: 0.18\n",
      "=> saving checkpoint\n",
      "Starting epoch 42\n",
      "learning rate: 0.00040442164047063304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.57it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.03\n",
      "===> val loss: 1.60, val iou: 0.16\n",
      "=> saving checkpoint\n",
      "Starting epoch 43\n",
      "learning rate: 0.0004021172421921706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.52it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.94\n",
      "===> val loss: 1.61, val iou: 0.18\n",
      "=> saving checkpoint\n",
      "Starting epoch 44\n",
      "learning rate: 0.0003998113756661346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:08<00:00,  2.57it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.97\n",
      "===> val loss: 1.63, val iou: 0.17\n",
      "=> saving checkpoint\n",
      "Starting epoch 45\n",
      "learning rate: 0.000397504030536037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.52it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 1.01\n",
      "===> val loss: 1.63, val iou: 0.21\n",
      "=> saving checkpoint\n",
      "Starting epoch 46\n",
      "learning rate: 0.0003951951963050278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.54it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.99\n",
      "===> val loss: 1.60, val iou: 0.17\n",
      "=> saving checkpoint\n",
      "Starting epoch 47\n",
      "learning rate: 0.00039288486233306853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.52it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.88\n",
      "===> val loss: 1.59, val iou: 0.21\n",
      "=> saving checkpoint\n",
      "Starting epoch 48\n",
      "learning rate: 0.0003905730178340304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.55it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.89\n",
      "===> val loss: 1.60, val iou: 0.19\n",
      "=> saving checkpoint\n",
      "Starting epoch 49\n",
      "learning rate: 0.0003882596518727134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:09<00:00,  2.54it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.93\n",
      "===> val loss: 1.73, val iou: 0.17\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "begin_training(train_dataset_dict, val_dataset_dict, model_dict, loss_dict, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "  Common causes for errors during training, may include : <br>\n",
    "    1. Not having <b>center images</b> for  <b>both</b> train and val directories  <br>\n",
    "    2. <b>Mismatch</b> between type of center-images saved in <b>01-data.ipynb</b> and the type of center chosen in this notebook (see the <b><a href=\"#center\"> center</a></b> parameter in the third code cell in this notebook)   <br>\n",
    "    3. In case of resuming training from a previous checkpoint, please ensure that the model weights are read from the correct directory, using the <b><a href=\"#resume\"> resume_path</a></b> parameter. Additionally, please ensure that the <b>save_dir</b> parameter for saving the model weights points to a relevant directory. \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EmbedSeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
